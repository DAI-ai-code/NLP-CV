{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7ed935d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0211739d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\dai\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\dai\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\dai\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\dai\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\dai\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\dai\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data] Downloading package indian to\n",
      "[nltk_data]     C:\\Users\\dai\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package indian is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt') # tokenization\n",
    "nltk.download('punkt_tab') # tokenization\n",
    "nltk.download('averaged_perceptron_tagger') #POS tagging\n",
    "nltk.download('wordnet') # wordnet vocabulary\n",
    "nltk.download('stopwords') #stopwords vocabulary\n",
    "nltk.download('omw-1.4') #stemming and lemmatization\n",
    "nltk.download('indian') #indian language POS tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e8e9b372",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
      "[nltk_data]     C:\\Users\\dai\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger_eng is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('averaged_perceptron_tagger_eng')  #POS Tagging for English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "54dda4c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package maxent_ne_chunker to\n",
      "[nltk_data]     C:\\Users\\dai\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data] Downloading package maxent_ne_chunker_tab to\n",
      "[nltk_data]     C:\\Users\\dai\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package maxent_ne_chunker_tab is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('maxent_ne_chunker') # NER Chunking\n",
    "nltk.download('maxent_ne_chunker_tab') # NER Chunking\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "574877a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'‡§Æ‡§Ç‡§ó‡§≤‡§µ‡§æ‡§∞'"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import indian\n",
    "nltk.corpus.indian.words('hindi.pos')[130]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2b284d58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28.666666666666668"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent = 'They told that their ages are 26 31 and 29 respectively.'\n",
    "num = [int(word) for word in sent.split() if word.isdigit()]\n",
    "sum(num) / len(num)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b55cb06",
   "metadata": {},
   "source": [
    "#### Word Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3cefa1c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['They',\n",
       " 'told',\n",
       " 'that',\n",
       " 'their',\n",
       " 'ages',\n",
       " 'are',\n",
       " '26',\n",
       " '31',\n",
       " 'and',\n",
       " '29',\n",
       " 'respectively',\n",
       " '.']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "tokens = word_tokenize(sent)\n",
    "tokens # punctuations symbols are also separated ! , ? ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "45f9cfed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Dr.',\n",
       " 'Desmukh',\n",
       " 'told',\n",
       " 'mrs.',\n",
       " 'sunita',\n",
       " '!',\n",
       " 'to',\n",
       " 'take',\n",
       " ',',\n",
       " 'rest',\n",
       " '.']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent1 = 'Dr. Desmukh told mrs. sunita!\\n to take, rest.'\n",
    "toks = word_tokenize(sent1)\n",
    "toks # recognizes dr., mrs. and . separately"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63886c08",
   "metadata": {},
   "source": [
    "### Sentence tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a0b8ffe8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Dr. Desmukh told mrs. sunita to take rest.']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import sent_tokenize\n",
    "sent_tokenize(sent1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "42f77f53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27.27272727272727"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find percentages of punctuations present in this sentence\n",
    "import string\n",
    "count = 0\n",
    "\n",
    "for i in toks:\n",
    "    if i in string.punctuation:\n",
    "         count+=1\n",
    "\n",
    "(count/len(toks))*100\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c14a3cd6",
   "metadata": {},
   "source": [
    "Checking on other languages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1bd46986",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = '''‡§§‡§ø‡§∏‡§∞‡•á ‡§á‡§Ç‡§ó‡•ç‡§∞‡§ú-‡§Æ‡§∞‡§æ‡§†‡§æ ‡§Ø‡•Å‡§¶‡•ç‡§ß ‡§π‡•á ‡§á.‡§∏. ‡•ß‡•Æ‡•ß‡•≠-‡•ß‡•Æ‡§Æ‡§ß‡•ç‡§Ø‡•á ‡§Æ‡§∞‡§æ‡§†‡•á ‡§®‡§ø‡§∞‡•ç‡§£‡§æ‡§Ø‡§ï ‡§Ø‡•Å‡§¶‡•ç‡§ß ‡§π‡•ã‡§§‡•á. \n",
    "          ‡§Ø‡§æ ‡§Ü‡§ß‡•Ä ‡§ù‡§æ‡§≤‡•á‡§≤‡•ç‡§Ø‡§æ ‡§¶‡•Å‡§∏‡§±‡•ç‡§Ø‡§æ ‡§â‡§∏‡§Ç‡§§ ‡§Æ‡§ø‡§≥‡§æ‡§≤‡•Ä. \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e7881e1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['‡§§‡§ø‡§∏‡§∞‡•á',\n",
       " '‡§á‡§Ç‡§ó‡•ç‡§∞‡§ú-‡§Æ‡§∞‡§æ‡§†‡§æ',\n",
       " '‡§Ø‡•Å‡§¶‡•ç‡§ß',\n",
       " '‡§π‡•á',\n",
       " '‡§á.‡§∏',\n",
       " '.',\n",
       " '‡•ß‡•Æ‡•ß‡•≠-‡•ß‡•Æ‡§Æ‡§ß‡•ç‡§Ø‡•á',\n",
       " '‡§Æ‡§∞‡§æ‡§†‡•á',\n",
       " '‡§®‡§ø‡§∞‡•ç‡§£‡§æ‡§Ø‡§ï',\n",
       " '‡§Ø‡•Å‡§¶‡•ç‡§ß',\n",
       " '‡§π‡•ã‡§§‡•á',\n",
       " '.',\n",
       " '‡§Ø‡§æ',\n",
       " '‡§Ü‡§ß‡•Ä',\n",
       " '‡§ù‡§æ‡§≤‡•á‡§≤‡•ç‡§Ø‡§æ',\n",
       " '‡§¶‡•Å‡§∏‡§±‡•ç‡§Ø‡§æ',\n",
       " '‡§â‡§∏‡§Ç‡§§',\n",
       " '‡§Æ‡§ø‡§≥‡§æ‡§≤‡•Ä',\n",
       " '.']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "word_tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a7cbcce0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['‡§§‡§ø‡§∏‡§∞‡•á ‡§á‡§Ç‡§ó‡•ç‡§∞‡§ú-‡§Æ‡§∞‡§æ‡§†‡§æ ‡§Ø‡•Å‡§¶‡•ç‡§ß ‡§π‡•á ‡§á.‡§∏.',\n",
       " '‡•ß‡•Æ‡•ß‡•≠-‡•ß‡•Æ‡§Æ‡§ß‡•ç‡§Ø‡•á ‡§Æ‡§∞‡§æ‡§†‡•á ‡§®‡§ø‡§∞‡•ç‡§£‡§æ‡§Ø‡§ï ‡§Ø‡•Å‡§¶‡•ç‡§ß ‡§π‡•ã‡§§‡•á.',\n",
       " '‡§Ø‡§æ ‡§Ü‡§ß‡•Ä ‡§ù‡§æ‡§≤‡•á‡§≤‡•ç‡§Ø‡§æ ‡§¶‡•Å‡§∏‡§±‡•ç‡§Ø‡§æ ‡§â‡§∏‡§Ç‡§§ ‡§Æ‡§ø‡§≥‡§æ‡§≤‡•Ä.']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import sent_tokenize\n",
    "sent_tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "70c87cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## how many times 'the' is present\n",
    "text = \"\"\"Pune (Marathi: Pu·πáƒì, pronounced [Ààpu…≥e] ‚ìò POO-nay), previously spelled in English as Poona (the official name until 1978),[15][16] is a city in the state of Maharashtra in the Deccan Plateau in Western India. It is the administrative headquarters of the Pune district, and of Pune division. In terms of the total amount of land under its jurisdiction, Pune is the largest city in Maharashtra by area, with a geographical area of 516.18 km2,[17] though by population it comes in a distant second to Mumbai. According to the 2011 Census of India, Pune has 7.2 million residents in the metropolitan region, making it the seventh-most populous metropolitan area in India.[18] The city of Pune is part of Pune Metropolitan Region.[19] Pune is one of the largest IT hubs in India.[20][21] It is also one of the most important automobile and manufacturing hubs of India. Pune is often referred to as the \"Oxford of the East\" because of its educational institutions.[22][23][24] It has been ranked \"the most liveable city in India\" several times.[25][26]\n",
    "Pune at different points in time has been ruled by the Rashtrakuta dynasty, Ahmadnagar Sultanate, the Mughals, and the Adil Shahi dynasty. In the 18th century, the city was part of the Maratha Empire, and the seat of the Peshwas, the prime ministers of the Maratha Empire.[27] Pune was seized by the British East India Company in the Third Anglo-Maratha War; it gained municipal status in 1858, the year in which Crown rule began. Many historical landmarks like Shaniwarwada, Shinde Chhatri, and Vishrambaug Wada date to this era. Historical sites from different eras dot the city.\n",
    "Pune has historically been a major cultural centre, with important figures like Dnyaneshwar, Shivaji, Tukaram, Baji Rao I, Balaji Baji Rao, Madhavrao I, Nana Fadnavis, Mahadev Govind Ranade, Gopal Krishna Gokhale, Mahatma Jyotirao Phule, Savitribai Phule, Gopal Ganesh Agarkar, Tarabai Shinde, Dhondo Keshav Karve, and Pandita Ramabai doing their life's work in Pune City or in an area that falls in Pune Metropolitan Region. Pune was a major centre of resistance to British Raj, with people like Gopal Krishna Gokhale, Bal Gangadhar Tilak playing leading roles in struggle for Indian independence in their times. \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6fa386b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = word_tokenize(text)\n",
    "\n",
    "the = [word for word in words if word.lower()=='the']\n",
    "len(the)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3fbf160e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words.count('the') + words.count('The')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24841a5b",
   "metadata": {},
   "source": [
    "WordPunctTokenizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8d3a2a46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['They',\n",
       " 'told',\n",
       " 'that',\n",
       " 'their',\n",
       " 'ages',\n",
       " 'are',\n",
       " '26',\n",
       " '31',\n",
       " 'and',\n",
       " '29',\n",
       " 'respectively',\n",
       " '.']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import WordPunctTokenizer\n",
    "tk = WordPunctTokenizer()\n",
    "tk.tokenize(sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7421e886",
   "metadata": {},
   "source": [
    "Space Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c18d3004",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Dr.', 'Desmukh', 'told', 'mrs.', 'sunita!\\n', 'to', 'take,', 'rest.']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import SpaceTokenizer\n",
    "\n",
    "tk = SpaceTokenizer() # considers only space, works like split(' ')\n",
    "tk.tokenize(sent1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b56557e1",
   "metadata": {},
   "source": [
    "Tab Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "fae927df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['This is', ' a test sentence.\\nHoping for no leopard.']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import TabTokenizer\n",
    "\n",
    "tk = TabTokenizer() # considers only tabs\n",
    "sents = 'This is\\t a test sentence.\\nHoping for no leopard.'\n",
    "tk.tokenize(sents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e7bb2fb",
   "metadata": {},
   "source": [
    "Line Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "1c654510",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['This is\\t a test sentence.', 'Hoping for no leopard.']"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import LineTokenizer\n",
    "\n",
    "tk = LineTokenizer() # considers only new line\n",
    "sents = 'This is\\t a test sentence.\\nHoping for no leopard.'\n",
    "tk.tokenize(sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "177f768e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['This', 'is', 'a', 'test', 'sentence.', 'Hoping', 'for', 'no', 'leopard.']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import WhitespaceTokenizer\n",
    "\n",
    "tk = WhitespaceTokenizer() # considers all white spaces, like split without parameter\n",
    "tk.tokenize(sents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c3797e1",
   "metadata": {},
   "source": [
    "MultiWord Expression Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "48b16c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import MWETokenizer\n",
    "\n",
    "sent = 'Chhatrapati Shivaji Maharaj was founder of Maratha Empire.'\n",
    "tk = MWETokenizer(separator=' ')\n",
    "tk.add_mwe(('Chhatrapati', 'Shivaji'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "5e6ac781",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Chhatrapati Shivaji',\n",
       " 'Maharaj',\n",
       " 'was',\n",
       " 'founder',\n",
       " 'of',\n",
       " 'Maratha',\n",
       " 'Empire',\n",
       " '.']"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tk.tokenize(word_tokenize(sent))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0aca447",
   "metadata": {},
   "source": [
    "Tweet Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "6f9a8681",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello',\n",
       " 'friends',\n",
       " '!',\n",
       " ':)',\n",
       " 'How',\n",
       " 'are',\n",
       " 'you',\n",
       " '?',\n",
       " 'Welcome',\n",
       " 'to',\n",
       " 'Python',\n",
       " 'Programming',\n",
       " '<3']"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = 'Hello friends!:) How are you? Welcome to Python Programming<3'\n",
    "\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "\n",
    "tk = TweetTokenizer()\n",
    "tk.tokenize(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "81228e8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['It', 'isüêÜ', '.', 'üò±üíÄ', 'Goddamn', ':', '(']"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = 'It isüêÜ. üò±üíÄ Goddamn:('\n",
    "word_tokenize(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "42efdf5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['It', 'is', 'üêÜ', '.', 'üò±', 'üíÄ', 'Goddamn', ':(']"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "tk = TweetTokenizer()\n",
    "tk.tokenize(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "baabb6ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "emojis = [emoji for emoji in tk.tokenize(data) if not emoji.isalnum() and emoji not in string.punctuation]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "a720c5d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['üêÜ', 'üò±', 'üíÄ', ':(']"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emojis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38fde0c0",
   "metadata": {},
   "source": [
    "###  custom tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "10782c9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['This',\n",
       " 'is',\n",
       " 'some',\n",
       " 'text',\n",
       " 'with',\n",
       " 'punctuation',\n",
       " '>',\n",
       " \"let's\",\n",
       " 'tokenize',\n",
       " 'it',\n",
       " 'Is',\n",
       " 'it',\n",
       " 'ok',\n",
       " '']"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "def custom_tokenizer(text):\n",
    "    return re.split(r\"[.,;?!\\s]+\", text)\n",
    "\n",
    "text = \"This is some text with punctuation > let's tokenize it. Is it ok?\"\n",
    "\n",
    "custom_tokenizer(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb3529fb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dnn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
