{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f7faa42c",
   "metadata": {},
   "source": [
    "1. Download the data from the link below using web scrapping:\n",
    "https://en.wikipedia.org/wiki/Mount_Everest\n",
    "Find the count of Total “Mount” in the text.\n",
    "Save the extracted plain text contents in file mount.txt in upper case.\n",
    "Print the title of this page.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "76e5e488",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk.tokenize import word_tokenize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "aff0b0c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = 'https://en.wikipedia.org/wiki/Mount_Everest'\n",
    "headers = {\n",
    "    'User-Agent':'Mozilla Chrome'\n",
    "}\n",
    "\n",
    "response = requests.get(url, headers=headers)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6578ec16",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "text = soup.get_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c9e8c815",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = word_tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "faa95c70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count of \"Mount\" in the text :  201\n"
     ]
    }
   ],
   "source": [
    "# count of mount\n",
    "print('count of \"Mount\" in the text : ', tokens.count('Mount'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4b3670ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving extracted plain text to mount.txt \n",
    "\n",
    "file = open(\"mount.txt\", \"w\")\n",
    "\n",
    "file.write(text.upper())\n",
    "\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "086287d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Mount Everest - Wikipedia'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# printing title of page\n",
    "soup.find('title').text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35ae2e2a",
   "metadata": {},
   "source": [
    "2. Read the following file\n",
    "\n",
    "https://www.london.ac.uk/sites/default/files/study-guides/introduction-to-\n",
    "natural-language-processing.pdf\n",
    "\n",
    "Print only page number 12 and 13 from it.\n",
    "Save this contents in a file nlp.txt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "22534c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pypdf import PdfReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bb9cea73",
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = PdfReader('../input/introduction-to-natural-language-processing.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5cf92cf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page 12:\n",
      "\n",
      "CO3354 Introduction to natural language processing\n",
      "2.2 Introduction\n",
      "People communicate in many different ways: through speaking and listening,\n",
      "making gestures, using specialised hand signals (such as when driving or directing\n",
      "trafﬁc), using sign languages for the deaf, or through various forms of text.\n",
      "By text we mean words that are written or printed on a ﬂat surface (paper, card,\n",
      "street signs and so on) or displayed on a screen or electronic device in order to be\n",
      "read by their intended recipient (or by whoever happens to be passing by).\n",
      "This course will focus only on the last of these: we will be concerned with various\n",
      "ways in which computer systems can analyse and interpret texts, and we will assume\n",
      "for convenience that these texts are presented in an electronic format. This is of\n",
      "course quite a reasonable assumption, given the huge amount of text we can access\n",
      "via the World Wide Web and the increasing availability of electronic versions of\n",
      "newspapers, novels, textbooks and indeed subject guides. This chapter introduces\n",
      "some essential concepts, techniques and terminology that will be applied in the rest\n",
      "of the course. Some material in this chapter is a little technical but no programming\n",
      "is involved at this stage.\n",
      "We will begin in section 2.3 by considering texts as strings of characters which can\n",
      "be broken up into sub-strings, and introduce some techniques for informally\n",
      "describing patterns of various kinds that occur in texts. Subsequently in section 2.4\n",
      "we will begin to motivate the analysis of texts in terms of hierarchical structures in\n",
      "which elements of various kinds can be embedded within each other, in a\n",
      "comparable way to the elements that make up an HTML web document. This section\n",
      "introduces some technical machinery such as: ﬁnite-state machines (FSMs), regular\n",
      "expressions, regular grammars and context-free grammars.\n",
      "2.3 Basic concepts\n",
      "2.3.1 Tokenised text and pattern matching\n",
      "One of the more basic operations that can be applied to a text is tokenising:\n",
      "breaking up a stream of characters into words, punctuation marks, numbers and\n",
      "other discrete items. So for example the character string\n",
      "“Dr. Watson, Mr. Sherlock Holmes”, said Stamford, introducing us.\n",
      "can be tokenised as in the following example, where each token is enclosed in single\n",
      "quotation marks:\n",
      "`\"' `Dr.' `Watson' `,' `Mr.' `Sherlock' `Holmes' `\"' `,'\n",
      "`said' `Stamford' `,' `introducing' `us' `.'\n",
      "At this level, words have not been classiﬁed into grammatical categories and we\n",
      "have very little indication of syntactic structure. Still, a fair amount of information\n",
      "may be obtained from relatively shallow analysis of tokenised text. For example,\n",
      "suppose we want to develop a procedure for ﬁnding all personal names in a given\n",
      "text. We know that personal names always start with capital letters, but that is not\n",
      "enough to distinguish them from names of countries, cities, companies, racehorses\n",
      "12 \n",
      "\n",
      "Page 13:\n",
      "\n",
      "Basic concepts\n",
      "and so on, or from capitalisation at the start of a sentence. Some additional ways to\n",
      "identify personal names include:\n",
      "Use of a title Dr., Mr., Mrs., Miss, Professor and so on.\n",
      "A capitalised word or words followed by a comma and a number, usually below\n",
      "100: this is a common way of referring to people in news reports, where the\n",
      "number stands for their age – for example Pierre Vinken, 61, . . .\n",
      "A capitalised word followed by a verb that usually applies to humans: said,\n",
      "reported, claimed, thought, argued . . . This can over-generate in the case of\n",
      "country or organisation names as in the Crown argues or Britain claimed.\n",
      "We can express these more concisely as follows, where jis the disjunction symbol,\n",
      "Word stands for a capitalised word and Int is an integer:\n",
      "(Dr. jProfessor jMr. jMrs. jMiss jMs) Word\n",
      "Word Word, Int\n",
      "Word (said jthought jbelieved jclaimed jargued j...)\n",
      "Learning activity\n",
      "1. Write down your own examples of names that match each of the above patterns.\n",
      "2. Pick a newspaper article or webpage that provides a variety of examples of people’s names. Do they\n",
      "match the patterns we have encoded above? If not, see if you can devise additional rules for\n",
      "recognising names and write them out in a similar format.\n",
      "2.3.2 Parts of speech\n",
      "A further stage in analysing text is to associate every token with a grammatical\n",
      "category or part of speech (POS). A number of different POS classiﬁcations have\n",
      "been developed within computational linguistics and we will see some examples in\n",
      "subsequent chapters. The following is a list of categories that are often encountered\n",
      "in general linguistics: you will be familiar with many of them already from learning\n",
      "the grammar of English or other languages, though some terms such as Determiner\n",
      "or Conjunction may be new to you.\n",
      "Noun ﬁsh, book, house, pen, procrastination, language\n",
      "Proper noun John, France, Barack, Goldsmiths, Python\n",
      "Verb loves, hates, studies, sleeps, thinks, is, has\n",
      "Adjective grumpy , sleepy , happy , bashful\n",
      "Adverb slowly , quickly , now, here, there\n",
      "Pronoun I, you, he, she, we, us, it, they\n",
      "Preposition in, on, at, by , around, with, without\n",
      "Conjunction and, but, or, unless\n",
      "Determiner the, a, an, some, many , few, 100\n",
      "13 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "final_text = ''\n",
    "pages = ['12', '13']\n",
    "for page in reader.pages:\n",
    "    text = page.extract_text()\n",
    "    if text[-2:] in pages:\n",
    "\n",
    "        print(f'Page {text[-2:]}:\\n')\n",
    "        print(text, '\\n')\n",
    "\n",
    "        final_text += 'Page ' +  text[-2:] + '\\n'\n",
    "        final_text += text[:-2] + '\\n'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3c6066ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(\"nlp.txt\", \"w\")\n",
    "\n",
    "file.write(final_text)\n",
    "\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4273d673",
   "metadata": {},
   "source": [
    "3. Read the file from the link givcen below:\n",
    "\n",
    "https://icml.cc/Conferences/2013/wp-content/uploads/2013/06/Machine-\n",
    "Learning-and-Natural-Language-Processing.docx\n",
    "\n",
    "Read and display first 5 paragraphs from it.\n",
    "Count total ‘The’ present in the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "32e82392",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spire.doc import Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0f4235f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "document = Document()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e6a9edbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "document.LoadFromFile('../input/Machine-Learning-and-Natural-Language-Processing.docx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3c078144",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = document.GetText()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "543a7314",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Warning: The document was created with Spire.Doc for Python.\n",
      "Machine Learning and Natural Language Processing\n",
      "Percy Liang\n",
      "Abstract: Machine learning plays a vital role in modern natural language processing (NLP), enabling the construction of robust machine translation, speech recognition, and question answering systems.  An underdeveloped but critical component required for further advancing the state-of-the-art is semantics, a topic that has been receiving increasing attention.  In this talk, I will first give an overview of various semantic models and the linguistic phenomena they seek to capture.  Then, I will walk through a model for question answering that learns logical forms in an unsupervised way.  Learning such a model requires dealing with both combinatorial explosions and non-convexities, heavily stressing existing machine learning techniques.  I will conclude by highlighting how these challenges point to exciting opportunities for developing new learning algorithms.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "1fca2599",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Evaluation Warning: The document was created with Spire.Doc for Python.',\n",
       " 'Machine Learning and Natural Language Processing\\r\\nPercy Liang\\r\\nAbstract: Machine learning plays a vital role in modern natural language processing (NLP), enabling the construction of robust machine translation, speech recognition, and question answering systems.',\n",
       " 'An underdeveloped but critical component required for further advancing the state-of-the-art is semantics, a topic that has been receiving increasing attention.',\n",
       " 'In this talk, I will first give an overview of various semantic models and the linguistic phenomena they seek to capture.',\n",
       " 'Then, I will walk through a model for question answering that learns logical forms in an unsupervised way.']"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# assuming first 5 lines as there is only one paragraph\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "sent_tokenize(text)[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c3bb9e03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# count of 'The'\n",
    "text.count('The')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a0eaf1d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
